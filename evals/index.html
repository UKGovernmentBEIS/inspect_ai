<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Inspect Evals – Inspect</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-listing/list.min.js"></script>
<script src="../site_libs/quarto-listing/quarto-listing.js"></script>
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script>

  window.document.addEventListener("DOMContentLoaded", function (_event) {
    const listingTargetEl = window.document.querySelector('#listing-evals .list');
    if (!listingTargetEl) {
      // No listing discovered, do not attach.
      return; 
    }

    const options = {
      valueNames: ['listing-arxiv','listing-categories','listing-contributors','listing-description','listing-group','listing-tasks','listing-title','listing-dependency','listing-tags',{ data: ['index'] },{ data: ['categories'] }],
      
      searchColumns: ["listing-arxiv","listing-categories","listing-contributors","listing-description","listing-group","listing-tasks","listing-title","listing-dependency","listing-tags"],
    };

    window['quarto-listings'] = window['quarto-listings'] || {};
    window['quarto-listings']['listing-evals'] = new List('listing-evals', options);

    if (window['quarto-listing-loaded']) {
      window['quarto-listing-loaded']();
    }
  });

  window.addEventListener('hashchange',() => {
    if (window['quarto-listing-loaded']) {
      window['quarto-listing-loaded']();
    }
  })
  </script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="evals.css">
<meta property="og:title" content="Inspect">
<meta property="og:description" content="Open-source framework for large language model evaluations">
<meta property="og:image" content="https://inspect.aisi.org.uk//images/inspect.png">
<meta property="og:site_name" content="Inspect">
<meta property="og:image:height" content="1258">
<meta property="og:image:width" content="2400">
<meta name="twitter:title" content="Inspect">
<meta name="twitter:description" content="Open-source framework for large language model evaluations">
<meta name="twitter:image" content="https://inspect.aisi.org.uk//images/inspect.png">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image-height" content="1258">
<meta name="twitter:image-width" content="2400">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="https://www.aisi.gov.uk/" class="navbar-brand navbar-brand-logo">
    <img src="../images/aisi-logo.svg" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="https://www.aisi.gov.uk/">
    <span class="navbar-title">Inspect AI</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html"> 
<span class="menu-text">User Guide</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../reference/index.html"> 
<span class="menu-text">Reference</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="../evals/index.html" aria-current="page"> 
<span class="menu-text">Evals</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/UKGovernmentBEIS/inspect_ai"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        
    <h5 class="quarto-listing-category-title">Categories</h5><div class="quarto-listing-category category-default"><div class="category" data-category="">All <span class="quarto-category-count">(68)</span></div><div class="category" data-category="Agent">Agent <span class="quarto-category-count">(13)</span></div><div class="category" data-category="Assistants">Assistants <span class="quarto-category-count">(5)</span></div><div class="category" data-category="Coding">Coding <span class="quarto-category-count">(11)</span></div><div class="category" data-category="Cybersecurity">Cybersecurity <span class="quarto-category-count">(8)</span></div><div class="category" data-category="Knowledge">Knowledge <span class="quarto-category-count">(14)</span></div><div class="category" data-category="Mathematics">Mathematics <span class="quarto-category-count">(5)</span></div><div class="category" data-category="Multimodal">Multimodal <span class="quarto-category-count">(5)</span></div><div class="category" data-category="Personality">Personality <span class="quarto-category-count">(1)</span></div><div class="category" data-category="Reasoning">Reasoning <span class="quarto-category-count">(18)</span></div><div class="category" data-category="Safeguards">Safeguards <span class="quarto-category-count">(4)</span></div><div class="category" data-category="Scheming">Scheming <span class="quarto-category-count">(2)</span></div></div></div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Inspect Evals</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p><a href="https://ukgovernmentbeis.github.io/inspect_evals/">Inspect Evals</a> is a repository of community contributed evaluations featuring implementations of many popular benchmarks and papers.</p>
<p>These evals can be <code>pip</code> installed and run with a single command against any model. They are also useful as a learning resource as they demonstrate a wide variety of evaluation types and techniques.</p>
<div id="listing-evals" class="quarto-listing quarto-listing-container-custom">

<ul class="list no-bullets">

 

  
  
    
<li class="group"><h2 href="#coding" class="anchored">Coding</h2></li>
    
  
<li class="example" data-index="0" data-categories="Coding">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-code"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/humaneval">
            HumanEval: Python Function Generation from Instructions
          </a>
        </div>
        <div class="listing-description text-secondary">Assesses how accurately language models can write correct Python functions based solely on natural-language instructions provided as docstrings.
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="1" data-categories="Coding">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-code"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/mbpp">
            MBPP: Basic Python Coding Challenges
          </a>
        </div>
        <div class="listing-description text-secondary">Measures the ability of language models to generate short Python programs from simple natural-language descriptions, testing basic coding proficiency.
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="2" data-categories="Coding,Agent">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-code"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/swe_bench">
            SWE-bench Verified: Resolving Real-World GitHub Issues
          </a>
        </div>
        <div class="listing-description text-secondary">Evaluates AI's ability to resolve genuine software engineering issues sourced from 12 popular Python GitHub repositories, reflecting realistic coding and debugging scenarios.
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="3" data-categories="Coding,Agent">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-code"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/mle_bench">
            MLE-bench: Evaluating Machine Learning Agents on Machine Learning Engineering
          </a>
        </div>
        <div class="listing-description text-secondary">Machine learning tasks drawn from 75 Kaggle competitions.
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="4" data-categories="Coding">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-code"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/ds1000">
            DS-1000: A Natural and Reliable Benchmark for Data Science Code Generation
          </a>
        </div>
        <div class="listing-description text-secondary">Code generation benchmark with a thousand data science problems spanning seven Python libraries.</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="5" data-categories="Coding">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-code"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/bigcodebench">
            BigCodeBench: Benchmarking Code Generation with Diverse Function Calls and Complex Instructions
          </a>
        </div>
        <div class="listing-description text-secondary">Python coding benchmark with 1,140 diverse questions drawing on numerous python libraries.
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="6" data-categories="Coding">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-code"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/class_eval">
            ClassEval: A Manually-Crafted Benchmark for Evaluating LLMs on Class-level Code Generation
          </a>
        </div>
        <div class="listing-description text-secondary">Evaluates LLMs on class-level code generation with 100 tasks constructed over 500 person-hours. The study shows that LLMs perform worse on class-level tasks compared to method-level tasks.
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="7" data-categories="Coding">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-code"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/scicode">
            SciCode: A Research Coding Benchmark Curated by Scientists
          </a>
        </div>
        <div class="listing-description text-secondary">SciCode tests the ability of language models to generate code to solve scientific research problems. It assesses models on 65 problems from mathematics, physics, chemistry, biology, and materials science.
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="8" data-categories="Coding">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-code"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/apps">
            APPS: Automated Programming Progress Standard
          </a>
        </div>
        <div class="listing-description text-secondary">APPS is a dataset for evaluating model performance on Python programming tasks across three difficulty levels consisting of 1,000 at introductory, 3,000 at interview, and 1,000 at competition level. The dataset consists of an additional 5,000 training samples, for a total of 10,000 total samples. We evaluate on questions from the test split, which consists of programming problems commonly found in coding interviews.
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="9" data-categories="Coding,Agent">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-code"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/core_bench">
            CORE-Bench
          </a>
        </div>
        <div class="listing-description text-secondary">Evaluate how well an LLM Agent is at computationally reproducing the results of a set of scientific papers.</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="10" data-categories="Coding">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-code"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/usaco">
            USACO: USA Computing Olympiad
          </a>
        </div>
        <div class="listing-description text-secondary">Evaluates language model performance on difficult Olympiad programming problems across four difficulty levels.
</div>
      </div>
    </div>
  
</li>

  
  
    
<li class="group"><h2 href="#assistants" class="anchored">Assistants</h2></li>
    
  
<li class="example" data-index="11" data-categories="Assistants,Agent">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-info-circle"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/gaia">
            GAIA: A Benchmark for General AI Assistants
          </a>
        </div>
        <div class="listing-description text-secondary">Proposes real-world questions that require a set of fundamental abilities such as reasoning, multi-modality handling, web browsing, and generally tool-use proficiency. GAIA questions are conceptually simple for humans yet challenging for most advanced AIs.
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="12" data-categories="Assistants,Agent">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-info-circle"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/osworld">
            OSWorld: Multimodal Computer Interaction Tasks
          </a>
        </div>
        <div class="listing-description text-secondary">Tests AI agents' ability to perform realistic, open-ended tasks within simulated computer environments, requiring complex interaction across multiple input modalities.
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="13" data-categories="Assistants,Agent">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-info-circle"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/assistant_bench">
            AssistantBench: Can Web Agents Solve Realistic and Time-Consuming Tasks?
          </a>
        </div>
        <div class="listing-description text-secondary">Tests whether AI agents can perform real-world time-consuming tasks on the web.
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="14" data-categories="Assistants">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-info-circle"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/sycophancy">
            Sycophancy Eval
          </a>
        </div>
        <div class="listing-description text-secondary">Evaluate sycophancy of language models across a variety of free-form text-generation tasks.
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="15" data-categories="Assistants">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-info-circle"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/mind2web">
            Mind2Web: Towards a Generalist Agent for the Web
          </a>
        </div>
        <div class="listing-description text-secondary">A dataset for developing and evaluating generalist agents for the web that can follow language instructions to complete complex tasks on any website.
</div>
      </div>
    </div>
  
</li>

  
  
    
<li class="group"><h2 href="#cybersecurity" class="anchored">Cybersecurity</h2></li>
    
  
<li class="example" data-index="16" data-categories="Cybersecurity,Agent">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-laptop"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/cybench">
            Cybench: Capture-The-Flag Cybersecurity Challenges
          </a>
        </div>
        <div class="listing-description text-secondary">Tests language models on cybersecurity skills using 40 practical, professional-level challenges taken from cybersecurity competitions, designed to cover various difficulty levels and security concepts.
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="17" data-categories="Cybersecurity,Agent">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-laptop"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/cybermetric">
            CyberMetric: A Benchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge
          </a>
        </div>
        <div class="listing-description text-secondary">Datasets containing 80, 500, 2000 and 10000 multiple-choice questions, designed to evaluate understanding across nine domains within cybersecurity
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="18" data-categories="Cybersecurity">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-laptop"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/cyberseceval_2">
            CyberSecEval_2: Cybersecurity Risk and Vulnerability Evaluation
          </a>
        </div>
        <div class="listing-description text-secondary">Assesses language models for cybersecurity risks, specifically testing their potential to misuse programming interpreters, vulnerability to malicious prompt injections, and capability to exploit known software vulnerabilities.
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="19" data-categories="Cybersecurity">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-laptop"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/cyberseceval_3">
            CYBERSECEVAL 3: Advancing the Evaluation of Cybersecurity Risks and Capabilities in Large Language Models
          </a>
        </div>
        <div class="listing-description text-secondary">Evaluates Large Language Models for cybersecurity risk to third parties, application developers and end users.
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="20" data-categories="Cybersecurity,Agent">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-laptop"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/gdm_capabilities/intercode_ctf">
            InterCode: Security and Coding Capture-the-Flag Challenges
          </a>
        </div>
        <div class="listing-description text-secondary">Tests AI's ability in coding, cryptography, reverse engineering, and vulnerability identification through practical capture-the-flag (CTF) cybersecurity scenarios.
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="21" data-categories="Cybersecurity,Agent">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-laptop"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/gdm_capabilities/in_house_ctf">
            GDM Dangerous Capabilities: Capture the Flag
          </a>
        </div>
        <div class="listing-description text-secondary">CTF challenges covering web app vulnerabilities, off-the-shelf exploits, databases, Linux privilege escalation, password cracking and spraying. Demonstrates tool use and sandboxing untrusted model code.
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="22" data-categories="Cybersecurity">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-laptop"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/sevenllm">
            SEvenLLM: A benchmark to elicit, and improve cybersecurity incident analysis and response abilities in LLMs for Security Events.
          </a>
        </div>
        <div class="listing-description text-secondary">Designed for analyzing cybersecurity incidents, which is comprised of two primary task categories: understanding and generation, with a further breakdown into 28 subcategories of tasks.
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="23" data-categories="Cybersecurity">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-laptop"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/sec_qa">
            SecQA: A Concise Question-Answering Dataset for Evaluating Large Language Models in Computer Security
          </a>
        </div>
        <div class="listing-description text-secondary">"Security Question Answering" dataset to assess LLMs' understanding and application of security principles. SecQA has "v1" and "v2" datasets of multiple-choice questions that aim to provide two levels of cybersecurity evaluation criteria. The questions were generated by GPT-4 based on the "Computer Systems Security: Planning for Success" textbook and vetted by humans.
</div>
      </div>
    </div>
  
</li>

  
  
    
<li class="group"><h2 href="#safeguards" class="anchored">Safeguards</h2></li>
    
  
<li class="example" data-index="24" data-categories="Safeguards">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-shield-lock"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/lab_bench">
            LAB-Bench: Measuring Capabilities of Language Models for Biology Research
          </a>
        </div>
        <div class="listing-description text-secondary">Tests LLMs and LLM-augmented agents abilities to answer questions on scientific research workflows in domains like chemistry, biology, materials science, as well as more general science tasks
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="25" data-categories="Safeguards,Agent">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-shield-lock"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/agentharm">
            AgentHarm: Harmfulness Potential in AI Agents
          </a>
        </div>
        <div class="listing-description text-secondary">Assesses whether AI agents might engage in harmful activities by testing their responses to malicious prompts in areas like cybercrime, harassment, and fraud, aiming to ensure safe behavior.
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="26" data-categories="Safeguards">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-shield-lock"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/wmdp">
            WMDP: Measuring and Reducing Malicious Use With Unlearning
          </a>
        </div>
        <div class="listing-description text-secondary">A dataset of 3,668 multiple-choice questions developed by a consortium of academics and technical consultants that serve as a proxy measurement of hazardous knowledge in biosecurity, cybersecurity, and chemical security.
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="27" data-categories="Safeguards">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-shield-lock"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/strong_reject">
            StrongREJECT: Measuring LLM susceptibility to jailbreak attacks
          </a>
        </div>
        <div class="listing-description text-secondary">A benchmark that evaluates the susceptibility of LLMs to various jailbreak attacks.
</div>
      </div>
    </div>
  
</li>

  
  
    
<li class="group"><h2 href="#mathematics" class="anchored">Mathematics</h2></li>
    
  
<li class="example" data-index="28" data-categories="Mathematics">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-calculator"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/mathematics">
            MATH: Measuring Mathematical Problem Solving
          </a>
        </div>
        <div class="listing-description text-secondary">Dataset of 12,500 challenging competition mathematics problems. Demonstrates fewshot prompting and custom scorers. NOTE: The dataset has been taken down due to a DMCA notice from The Art of Problem Solving.
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="29" data-categories="Mathematics">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-calculator"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/gsm8k">
            GSM8K: Grade School Math Word Problems
          </a>
        </div>
        <div class="listing-description text-secondary">Measures how effectively language models solve realistic, linguistically rich math word problems suitable for grade-school-level mathematics.
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="30" data-categories="Mathematics,Multimodal">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-calculator"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/mathvista">
            MathVista: Visual Math Problem-Solving
          </a>
        </div>
        <div class="listing-description text-secondary">Tests AI models on math problems that involve interpreting visual elements like diagrams and charts, requiring detailed visual comprehension and logical reasoning.
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="31" data-categories="Mathematics">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-calculator"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/mgsm">
            MGSM: Multilingual Grade School Math
          </a>
        </div>
        <div class="listing-description text-secondary">Extends the original GSM8K dataset by translating 250 of its problems into 10 typologically diverse languages.
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="32" data-categories="Mathematics">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-calculator"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/aime2024">
            AIME 2024: Problems from the American Invitational Mathematics Examination
          </a>
        </div>
        <div class="listing-description text-secondary">A benchmark for evaluating AI's ability to solve challenging mathematics problems from AIME - a prestigious high school mathematics competition.
</div>
      </div>
    </div>
  
</li>

  
  
    
<li class="group"><h2 href="#reasoning" class="anchored">Reasoning</h2></li>
    
  
<li class="example" data-index="33" data-categories="Reasoning,Multimodal">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-boxes"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/vstar_bench">
            V*Bench: A Visual QA Benchmark with Detailed High-resolution Images
          </a>
        </div>
        <div class="listing-description text-secondary">V*Bench is a visual question &amp; answer benchmark that evaluates MLLMs in their ability to process high-resolution and visually crowded images to find and focus on small details.
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="34" data-categories="Reasoning">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-boxes"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/arc">
            ARC: AI2 Reasoning Challenge
          </a>
        </div>
        <div class="listing-description text-secondary">Dataset of natural, grade-school science multiple-choice questions (authored for human tests).</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="35" data-categories="Reasoning">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-boxes"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/hellaswag">
            HellaSwag: Commonsense Event Continuation
          </a>
        </div>
        <div class="listing-description text-secondary">Tests models' commonsense reasoning abilities by asking them to select the most likely next step or continuation for a given everyday situation.
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="36" data-categories="Reasoning">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-boxes"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/piqa">
            PIQA: Physical Commonsense Reasoning Test
          </a>
        </div>
        <div class="listing-description text-secondary">Measures the model's ability to apply practical, everyday commonsense reasoning about physical objects and scenarios through simple decision-making questions.
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="37" data-categories="Reasoning">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-boxes"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/infinite_bench">
            ∞Bench: Extending Long Context Evaluation Beyond 100K Tokens
          </a>
        </div>
        <div class="listing-description text-secondary">LLM benchmark featuring an average data length surpassing 100K tokens. Comprises synthetic and realistic tasks spanning diverse domains in English and Chinese.
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="38" data-categories="Reasoning">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-boxes"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/bbh">
            BBH: Challenging BIG-Bench Tasks
          </a>
        </div>
        <div class="listing-description text-secondary">Tests AI models on a suite of 23 challenging BIG-Bench tasks that previously proved difficult even for advanced language models to solve.
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="39" data-categories="Reasoning">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-boxes"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/boolq">
            BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions
          </a>
        </div>
        <div class="listing-description text-secondary">Reading comprehension dataset that queries for complex, non-factoid information, and require difficult entailment-like inference to solve.
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="40" data-categories="Reasoning,Multimodal">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-boxes"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/docvqa">
            DocVQA: A Dataset for VQA on Document Images
          </a>
        </div>
        <div class="listing-description text-secondary">DocVQA is a Visual Question Answering benchmark that consists of 50,000 questions covering 12,000+ document images. This implementation solves and scores the "validation" split.
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="41" data-categories="Reasoning">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-boxes"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/drop">
            DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs
          </a>
        </div>
        <div class="listing-description text-secondary">Evaluates reading comprehension where models must resolve references in a question, perhaps to multiple input positions, and perform discrete operations over them (such as addition, counting, or sorting).
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="42" data-categories="Reasoning">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-boxes"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/winogrande">
            WINOGRANDE: An Adversarial Winograd Schema Challenge at Scale
          </a>
        </div>
        <div class="listing-description text-secondary">Set of 273 expert-crafted pronoun resolution problems originally designed to be unsolvable for statistical models that rely on selectional preferences or word associations.
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="43" data-categories="Reasoning">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-boxes"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/race_h">
            RACE-H: A benchmark for testing reading comprehension and reasoning abilities of neural models
          </a>
        </div>
        <div class="listing-description text-secondary">Reading comprehension tasks collected from the English exams for middle and high school Chinese students in the age range between 12 to 18.
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="44" data-categories="Reasoning,Multimodal">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-boxes"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/mmmu">
            MMMU: Multimodal College-Level Understanding and Reasoning
          </a>
        </div>
        <div class="listing-description text-secondary">Assesses multimodal AI models on challenging college-level questions covering multiple academic subjects, requiring detailed visual interpretation, in-depth reasoning, and both multiple-choice and open-ended answering abilities.
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="45" data-categories="Reasoning">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-boxes"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/squad">
            SQuAD: A Reading Comprehension Benchmark requiring reasoning over Wikipedia articles
          </a>
        </div>
        <div class="listing-description text-secondary">Set of 100,000+ questions posed by crowdworkers on a set of Wikipedia articles, where the answer to each question is a segment of text from the corresponding reading passage.
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="46" data-categories="Reasoning">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-boxes"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/ifeval">
            IFEval: Instruction-Following Evaluation
          </a>
        </div>
        <div class="listing-description text-secondary">Evaluates how well language models can strictly follow detailed instructions, such as writing responses with specific word counts or including required keywords.
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="47" data-categories="Reasoning">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-boxes"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/musr">
            MuSR: Testing the Limits of Chain-of-thought with Multistep Soft Reasoning
          </a>
        </div>
        <div class="listing-description text-secondary">Evaluating models on multistep soft reasoning tasks in the form of free text narratives.
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="48" data-categories="Reasoning">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-boxes"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/niah">
            Needle in a Haystack (NIAH): In-Context Retrieval Benchmark for Long Context LLMs
          </a>
        </div>
        <div class="listing-description text-secondary">NIAH evaluates in-context retrieval ability of long context LLMs by testing a model's ability to extract factual information from long-context inputs.
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="49" data-categories="Reasoning">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-boxes"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/paws">
            PAWS: Paraphrase Adversaries from Word Scrambling
          </a>
        </div>
        <div class="listing-description text-secondary">Evaluating models on the task of paraphrase detection by providing pairs of sentences that are either paraphrases or not.
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="50" data-categories="Reasoning,Multimodal">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-boxes"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/mmiu">
            MMIU: Multimodal Multi-image Understanding for Evaluating Large Vision-Language Models
          </a>
        </div>
        <div class="listing-description text-secondary">A comprehensive dataset designed to evaluate Large Vision-Language Models (LVLMs) across a wide range of multi-image tasks. The dataset encompasses 7 types of multi-image relationships, 52 tasks, 77K images, and 11K meticulously curated multiple-choice questions.</div>
      </div>
    </div>
  
</li>

  
  
    
<li class="group"><h2 href="#knowledge" class="anchored">Knowledge</h2></li>
    
  
<li class="example" data-index="51" data-categories="Knowledge">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-book"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/mmlu">
            MMLU: Measuring Massive Multitask Language Understanding
          </a>
        </div>
        <div class="listing-description text-secondary">Evaluate models on 57 tasks including elementary mathematics, US history, computer science, law, and more.
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="52" data-categories="Knowledge">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-book"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/mmlu_pro">
            MMLU-Pro: Advanced Multitask Knowledge and Reasoning Evaluation
          </a>
        </div>
        <div class="listing-description text-secondary">An advanced benchmark that tests both broad knowledge and reasoning capabilities across many subjects, featuring challenging questions and multiple-choice answers with increased difficulty and complexity.
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="53" data-categories="Knowledge">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-book"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/gpqa">
            GPQA: Graduate-Level STEM Knowledge Challenge
          </a>
        </div>
        <div class="listing-description text-secondary">Contains challenging multiple-choice questions created by domain experts in biology, physics, and chemistry, designed to test advanced scientific understanding beyond basic internet searches. Experts at PhD level in the corresponding domains reach 65% accuracy.
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="54" data-categories="Knowledge">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-book"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/commonsense_qa">
            CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge
          </a>
        </div>
        <div class="listing-description text-secondary">Evaluates an AI model's ability to correctly answer everyday questions that rely on basic commonsense knowledge and understanding of the world.
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="55" data-categories="Knowledge">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-book"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/truthfulqa">
            TruthfulQA: Measuring How Models Mimic Human Falsehoods
          </a>
        </div>
        <div class="listing-description text-secondary">Measure whether a language model is truthful in generating answers to questions using questions that some humans would answer falsely due to a false belief or misconception.
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="56" data-categories="Knowledge">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-book"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/xstest">
            XSTest: A benchmark for identifying exaggerated safety behaviours in LLM's
          </a>
        </div>
        <div class="listing-description text-secondary">Dataset with 250 safe prompts across ten prompt types that well-calibrated models should not refuse, and 200 unsafe prompts as contrasts that models, for most applications, should refuse.
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="57" data-categories="Knowledge">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-book"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/pubmedqa">
            PubMedQA: A Dataset for Biomedical Research Question Answering
          </a>
        </div>
        <div class="listing-description text-secondary">Biomedical question answering (QA) dataset collected from PubMed abstracts.
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="58" data-categories="Knowledge">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-book"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/agieval">
            AGIEval: A Human-Centric Benchmark for Evaluating Foundation Models
          </a>
        </div>
        <div class="listing-description text-secondary">AGIEval is a human-centric benchmark specifically designed to evaluate the general abilities of foundation models in tasks pertinent to human cognition and problem-solving.
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="59" data-categories="Knowledge">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-book"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/livebench">
            LiveBench: A Challenging, Contamination-Free LLM Benchmark
          </a>
        </div>
        <div class="listing-description text-secondary">LiveBench is a benchmark designed with test set contamination and objective evaluation in mind by releasing new questions regularly, as well as having questions based on recently-released datasets. Each question has verifiable, objective ground-truth answers, allowing hard questions to be scored accurately and automatically, without the use of an LLM judge.
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="60" data-categories="Knowledge">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-book"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/onet">
            O-NET: A high-school student knowledge test
          </a>
        </div>
        <div class="listing-description text-secondary">Questions and answers from the Ordinary National Educational Test (O-NET), administered annually by the National Institute of Educational Testing Service to Matthayom 6 (Grade 12 / ISCED 3) students in Thailand. The exam contains six subjects: English language, math, science, social knowledge, and Thai language. There are questions with multiple-choice and true/false answers. Questions can be in either English or Thai.
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="61" data-categories="Knowledge">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-book"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/hle">
            Humanity's Last Exam
          </a>
        </div>
        <div class="listing-description text-secondary">Humanity's Last Exam (HLE) is a multi-modal benchmark at the frontier of human knowledge, designed to be the final closed-ended academic benchmark of its kind with broad subject coverage. Humanity's Last Exam consists of 3,000 questions across dozens of subjects, including mathematics, humanities, and the natural sciences. HLE is developed globally by subject-matter experts and consists of multiple-choice and short-answer questions suitable for automated grading.
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="62" data-categories="Knowledge">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-book"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/simpleqa">
            SimpleQA: Measuring short-form factuality in large language models
          </a>
        </div>
        <div class="listing-description text-secondary">A benchmark that evaluates the ability of language models to answer short, fact-seeking questions.
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="63" data-categories="Knowledge">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-book"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/pre_flight">
            Pre-Flight: Aviation Operations Knowledge Evaluation
          </a>
        </div>
        <div class="listing-description text-secondary">Tests model understanding of aviation regulations including ICAO annexes, flight dispatch rules, pilot procedures, and airport ground operations safety protocols.
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="64" data-categories="Knowledge">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-book"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/air_bench">
            AIR Bench: AI Risk Benchmark
          </a>
        </div>
        <div class="listing-description text-secondary">A safety benchmark evaluating language models against risk categories derived from government regulations and company policies.
</div>
      </div>
    </div>
  
</li>

  
  
    
<li class="group"><h2 href="#scheming" class="anchored">Scheming</h2></li>
    
  
<li class="example" data-index="65" data-categories="Scheming,Agent">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-person-gear"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/gdm_capabilities/self_reasoning">
            GDM Dangerous Capabilities: Self-Reasoning
          </a>
        </div>
        <div class="listing-description text-secondary">Test AI's ability to reason about its environment.
</div>
      </div>
    </div>
  
</li>

  
    
  
<li class="example" data-index="66" data-categories="Scheming,Agent">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-person-gear"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/gdm_capabilities/stealth">
            GDM Dangerous Capabilities: Stealth
          </a>
        </div>
        <div class="listing-description text-secondary">Test AI's ability to reason about and circumvent oversight.
</div>
      </div>
    </div>
  
</li>

  
  
    
<li class="group"><h2 href="#personality" class="anchored">Personality</h2></li>
    
  
<li class="example" data-index="67" data-categories="Personality">
    <div class="example-card">
      <div class="example-icon fs-5">
        <i class="bi bi-people"></i>
      </div>
      <div class="example-info">
        <div class="listing-title">
          <a href="https://github.com/UKGovernmentBEIS/inspect_evals/tree/main/src/inspect_evals/personality">
            Personality
          </a>
        </div>
        <div class="listing-description text-secondary">An evaluation suite consisting of multiple personality tests that can be applied to LLMs.
Its primary goals are twofold:
  1. Assess a model's default personality: the persona it naturally exhibits without specific prompting.  
  2. Evaluate whether a model can embody a specified persona**: how effectively it adopts certain personality traits when prompted or guided.
</div>
      </div>
    </div>
  
</li>
  
</ul>
<div class="listing-no-matching d-none">
No matching items
</div>
</div>




</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/inspect\.aisi\.org\.uk\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      const annoteTargets = window.document.querySelectorAll('.code-annotation-anchor');
      for (let i=0; i<annoteTargets.length; i++) {
        const annoteTarget = annoteTargets[i];
        const targetCell = annoteTarget.getAttribute("data-target-cell");
        const targetAnnotation = annoteTarget.getAttribute("data-target-annotation");
        const contentFn = () => {
          const content = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          if (content) {
            const tipContent = content.cloneNode(true);
            tipContent.classList.add("code-annotation-tip-content");
            return tipContent.outerHTML;
          }
        }
        const config = {
          allowHTML: true,
          content: contentFn,
          onShow: (instance) => {
            selectCodeLines(instance.reference);
            instance.reference.classList.add('code-annotation-active');
            window.tippy.hideAll();
          },
          onHide: (instance) => {
            unselectCodeLines();
            instance.reference.classList.remove('code-annotation-active');
          },
          maxWidth: 300,
          delay: [50, 0],
          duration: [200, 0],
          offset: [5, 10],
          arrow: true,
          trigger: 'click',
          appendTo: function(el) {
            return el.parentElement.parentElement.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'quarto',
          placement: 'right',
          positionFixed: true,
          popperOptions: {
            modifiers: [
            {
              name: 'flip',
              options: {
                flipVariations: false, // true by default
                allowedAutoPlacements: ['right'],
                fallbackPlacements: ['right', 'top', 'top-start', 'top-end', 'bottom', 'bottom-start', 'bottom-end', 'left'],
              },
            },
            {
              name: 'preventOverflow',
              options: {
                mainAxis: false,
                altAxis: false
              }
            }
            ]        
          }      
        };
        window.tippy(annoteTarget, config); 
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
    <a class="nav-link" href="https://aisi.gov.uk/">
<p>UK AI Security Institute</p>
</a>
  </li>  
</ul>
    </div>   
    <div class="nav-footer-center">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
    <a class="nav-link" href="https://github.com/UKGovernmentBEIS/inspect_ai">
<p>Code</p>
</a>
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="https://github.com/UKGovernmentBEIS/inspect_ai/blob/main/CHANGELOG.md">
<p>Changelog</p>
</a>
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="https://github.com/UKGovernmentBEIS/inspect_ai/blob/main/LICENSE">
<p>License</p>
</a>
  </li>  
    <li class="nav-item">
    <a class="nav-link" href="https://github.com/UKGovernmentBEIS/inspect_ai/issues">
<p>Issues</p>
</a>
  </li>  
</ul>
    <div class="toc-actions"><ul><li><a href="https://github.com/UKGovernmentBEIS/inspect_ai/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://x.com/AISecurityInst">
      <i class="bi bi-twitter" role="img" aria-label="UK AI Security Institute Twitter">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/UKGovernmentBEIS/inspect_ai/">
      <i class="bi bi-github" role="img" aria-label="Inspect on GitHub">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>




</body></html>