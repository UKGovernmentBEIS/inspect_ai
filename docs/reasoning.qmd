---
title: Reasoning
---

::: {.callout-note appearance="simple"}
The reasoning features described below are currently available only in the development version of Inspect. To install the development version from GitHub:

``` bash
pip install git+https://github.com/UKGovernmentBEIS/inspect_ai
```
:::

## Overview

Reasoning models like OpenAI o1 and o3, Anthropic's Claude Sonnet 3.7, Google's Gemini 2.0 Flash Thinking, and DeepSeek's r1 have some additional options that can be used to tailor their behaviour. They also in some cases make available full or partial reasoning traces for the chains of thought that led to their response.

In this article we'll first cover the basics of [Reasoning Content](#reasoning-content) and [Reasoning Options](#reasoning-options), then cover the usage and options supported by various reasoning models.

## Reasoning Content {#reasoning-content}

Many reasoning models allow you to see their underlying chain of thought in a special "thinking" or reasoning block. While reasoning is presented in different ways depending on the model, in the Inspect API it is normalised into `ContentReasoning` blocks which are parallel to `ContentText`, `ContentImage`, etc.

Reasoning blocks are presented in their own region in both Inspect View and in terminal conversation views.

While reasoning content isn't made available in a standard fashion across models, Inspect does attempt to capture it using several heuristics, including responses that include a `reasoning` or `reasoning_content` field in the assistant message, assistant content that includes `<think></think>` tags, as well as using explicit APIs for models that support them (e.g. Claude 3.7).

## Reasoning Options {#reasoning-options}

The following reasoning options are available from the CLI and within `GenerateConfig`:

| Option              | Description                                                                           | Default  | Models       |
|------------------|-------------------------------------|---------|---------|
| `reasoning_effort`  | Constrains effort on reasoning for reasoning models (`low`, `medium`, or `high`)      | `medium` | OpenAI o1/o3 |
| `reasoning_tokens`  | Maximum number of tokens to use for reasoning.                                        | (none)   | Claude 3.7   |
| `reasoning_history` | Include reasoning in message history sent to model (`none`, `all`, `last`, or `auto`) | `auto`   | All models   |

As you can see from above, models have different means of specifying the tokens to allocate for reasoning (`reasoning_effort` and `reasoning_tokens`). The two options don't map precisely into each other, so if you are doing an evaluation with multiple reasoning models you should specify both. For example:

``` python
 eval(
    task,
    model=["openai/o3-mini","anthropic/anthropic/claude-3-7-sonnet-20250219"],
    reasoning_effort="medium",
    reasoning_tokens=4096
 )
```

The `reasoning_history` option lets you control how much of the model's previous reasoning is presented in the message history sent to `generate()`. The default is `auto`, which uses a provider-specific recommended default (normally `all`). Use `last` to not let the reasoning overwhelm the context window.

## OpenAI o1/o3

## Claude 3.7 Sonnet

## Google Flash Thinking

## DeepSeek r1